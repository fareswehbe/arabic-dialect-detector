{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70504fcb-2336-4da3-b634-18469accf2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import folium\n",
    "import webbrowser\n",
    "from matplotlib.colors import LinearSegmentedColormap, rgb2hex\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3fc366-7b50-4af6-96e0-575802e401cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/new_arabic_dialect_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a96c59-068a-478c-ad3a-ade04a5b16d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n",
      "C:\\Users\\Fares\\AppData\\Local\\Temp\\ipykernel_2376\\15832291.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(dialect_sentences)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame to store the sampled sentences\n",
    "new_data = pd.DataFrame(columns=['sentence', 'dialect', 'sentence_clean'])\n",
    "\n",
    "# Iterate over each dialect\n",
    "dialects = data['dialect'].unique()\n",
    "for dialect in dialects:\n",
    "    # Select 100 sentences from each dialect\n",
    "    dialect_sentences = data[data['dialect'] == dialect].sample(n=1000, random_state=42)\n",
    "    \n",
    "    # Append the sampled sentences to the new DataFrame\n",
    "    new_data = new_data.append(dialect_sentences)\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "new_data = new_data.fillna('')\n",
    "new_data.to_csv('../data/data_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be54dcc0-95f8-4780-9553-f34a46e9f83f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4753                                هـ بناخدوله وحدة الزوي\n",
      "3194       صارت الساعه بدونك واقفه الدقايق حالفه تمر بلياك\n",
      "17668    نادرا هتلاقي حد مجربش الحشيش أو الكحول ظنا منه...\n",
      "16608                      بأشر وبعطيك ولا يهمك راسي حارتك\n",
      "16217       فيه تلاعب المقطع ليش يقطع شوي أثناء رفع الكورة\n",
      "                               ...                        \n",
      "7471     نريد بعد واحد نزيه يجيب تزين واحد شغال يجيب شغ...\n",
      "2980            مادري واله انتي راد تويت مادري عاد شنو كان\n",
      "12933                             وين بيذيعون الإطلاق ومتى\n",
      "16598                         قبل نمشي مكن تعطيني كم دقيقة\n",
      "7632                        تستاهل زيون كم ريتويت حساب ميز\n",
      "Name: sentence_clean, Length: 15200, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "new_data = pd.read_csv('../data/data_sample.csv')\n",
    "\n",
    "X = new_data.sentence_clean\n",
    "y = new_data.dialect\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=new_data['dialect'])\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a286d56a-a39f-410d-a52f-1f77a92b1763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 3))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initizalize the vectorizer with max nr words and ngrams (1: single words, 2: two words in a row)\n",
    "vectorizer_tfidf = TfidfVectorizer(ngram_range=(1,3))\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer_tfidf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb164ec-06c4-4b64-8da2-334ee5a7d68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "classifier_tfidf_SVC = SVC(probability = True)\n",
    "\n",
    "model_tfidf_SVC = Pipeline([\n",
    "    (\"vectorizer\", vectorizer_tfidf),\n",
    "    #(\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"classifier\", classifier_tfidf_SVC)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    \"classifier__C\": [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(model_tfidf_SVC, param_grid, cv=cv, scoring=\"accuracy\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af72d60-2593-4296-91fb-78df2c9de51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(best_params)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c95ee-98df-40cf-9a8b-3bf1fd683bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with the best parameters\n",
    "model_tfidf_SVC.set_params(**best_params)\n",
    "model_tfidf_SVC.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_tfidf_SVC, '../models/model_tfidf_SVC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ce634f-2409-4d6d-bc41-1e7869487090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training data: 41.3%\n",
      "Accuracy Test data: 41.8%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "saved_model_tfidf_SVC = joblib.load('../models/model_tfidf_SVC.pkl')\n",
    "\n",
    "predicted_train_tfidf_SVC = saved_model_tfidf_SVC.predict(X_train)\n",
    "accuracy_train_tfidf_SVC = accuracy_score(y_train, predicted_train_tfidf_SVC)\n",
    "print('Accuracy Training data: {:.1%}'.format(accuracy_train_tfidf_SVC))\n",
    "\n",
    "predicted_test_tfidf_SVC = saved_model_tfidf_SVC.predict(X_test)\n",
    "accuracy_test_tfidf_SVC = accuracy_score(y_test, predicted_test_tfidf_SVC)\n",
    "print('Accuracy Test data: {:.1%}'.format(accuracy_test_tfidf_SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b929f317-a06b-427b-9b2f-6490837ffe8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AE       0.21      0.23      0.22       200\n",
      "          BH       0.23      0.24      0.24       200\n",
      "          DZ       0.45      0.45      0.45       200\n",
      "          EG       0.56      0.56      0.56       200\n",
      "          IQ       0.50      0.51      0.50       200\n",
      "          JO       0.31      0.30      0.31       200\n",
      "          KW       0.29      0.28      0.29       200\n",
      "          LB       0.45      0.49      0.47       200\n",
      "          LY       0.46      0.45      0.45       200\n",
      "          MA       0.75      0.63      0.69       200\n",
      "         MSA       0.88      0.84      0.86       200\n",
      "          OM       0.26      0.30      0.28       200\n",
      "          PL       0.33      0.35      0.34       200\n",
      "          QA       0.29      0.30      0.29       200\n",
      "          SA       0.30      0.34      0.31       200\n",
      "          SD       0.64      0.54      0.59       200\n",
      "          SY       0.38      0.33      0.35       200\n",
      "          TN       0.70      0.49      0.58       200\n",
      "          YE       0.26      0.30      0.28       200\n",
      "\n",
      "    accuracy                           0.42      3800\n",
      "   macro avg       0.43      0.42      0.42      3800\n",
      "weighted avg       0.43      0.42      0.42      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance_metrics = classification_report(y_test, predicted_test_tfidf_SVC)\n",
    "print(performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa3a96-0b40-4d44-a9d6-ab935a4744d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data = pd.read_csv('../data/test_models.csv')\n",
    "model_data = model_data.append({'Model': 'SVC', 'Performance Metrics': performance_metrics, 'Accuracy': accuracy_test_tfidf_SVC}, ignore_index=True)\n",
    "model_data.to_csv('../data/test_models.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9d130b-1d65-4bac-922c-6eca907634bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data = confusion_matrix(y_test, predicted_test_tfidf_SVC,labels=[\"MA\", \"DZ\",\"TN\",\"LY\",\"EG\",\"SD\",\"LB\",\"PL\",\"SY\",\"JO\",\"OM\",\"BH\",\"KW\",\"SA\",\"AE\",\"QA\",\"IQ\",\"YE\",\"MSA\"])\n",
    "data_cm = pd.DataFrame(data, columns=[\"MA\", \"DZ\",\"TN\",\"LY\",\"EG\",\"SD\",\"LB\",\"PL\",\"SY\",\"JO\",\"OM\",\"BH\",\"KW\",\"SA\",\"AE\",\"QA\",\"IQ\",\"YE\",\"MSA\"], index = [\"MA\", \"DZ\",\"TN\",\"LY\",\"EG\",\"SD\",\"LB\",\"PL\",\"SY\",\"JO\",\"OM\",\"BH\",\"KW\",\"SA\",\"AE\",\"QA\",\"IQ\",\"YE\",\"MSA\"])\n",
    "data_cm.index.name = 'Actual'\n",
    "data_cm.columns.name = 'Predicted'\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "sns.heatmap(data_cm, cbar=False, annot=True, cmap=cmap, square=True, fmt='.0f',\n",
    "            annot_kws={'size':10})\n",
    "plt.title('Actuals vs Predicted')\n",
    "plt.savefig('../data/figs/SVC_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd9a7f-d71a-491f-b223-de2dc6ea4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_coordinates(country,proximity_score):\n",
    "    # Define a dictionary with the latitude and longitude coordinates for each Arabic country\n",
    "    country_coordinates = {\n",
    "        \"MA\": [31.7917, -7.0926],\n",
    "        \"DZ\": [36.7538, 3.0588],\n",
    "        \"TN\": [33.8869, 9.5375],\n",
    "        \"LY\": [26.3351, 17.2283],\n",
    "        \"EG\": [26.8206, 30.8025],\n",
    "        \"SD\": [15.5007, 32.5599],\n",
    "        \"LB\": [33.8547, 35.8623],\n",
    "        \"PL\": [33.8547, 35.8623],\n",
    "        \"SY\": [34.8021, 38.9968],\n",
    "        \"JO\": [30.5852, 36.2384],\n",
    "        \"OM\": [21.4735, 55.9754],\n",
    "        \"BH\": [26.0667, 50.5577],\n",
    "        \"KW\": [29.3117, 47.4818],\n",
    "        \"SA\": [23.8859, 45.0792],\n",
    "        \"AE\": [23.4241, 53.8478],\n",
    "        \"QA\": [25.3548, 51.1839],\n",
    "        \"IQ\": [33.2232, 43.6793],\n",
    "        \"YE\": [15.5527, 48.5164],\n",
    "        \"MSA\": [20.0000, 40.0000]  # Placeholder coordinates for MSA\n",
    "    }\n",
    "    \n",
    "    # Define the gradient colors from yellow to red\n",
    "    colors = [\"red\",\"orange\",\"yellow\",\"green\"]\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n",
    "\n",
    "    # Map the proximity score to the gradient colormap\n",
    "    color_rgb = cmap(proximity_score)\n",
    "\n",
    "    # Convert the RGB color to hexadecimal format\n",
    "    color_hex = rgb2hex(color_rgb)\n",
    "    print(color_hex)\n",
    "\n",
    "    return country_coordinates.get(country, [0, 0]), color_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96a58f2-773c-4319-950e-7ec26df8cf2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_dialect():\n",
    "    sentence = entry.get()\n",
    "    minimum_probability = float('inf')\n",
    "    maximum_probability = float('-inf')\n",
    "\n",
    "    if sentence.strip() == '':\n",
    "        messagebox.showerror(\"Error\", \"Please enter an Arabic sentence.\")\n",
    "        return\n",
    "\n",
    "    prediction = saved_model_tfidf_SVC.predict([sentence])\n",
    "    probabilities = saved_model_tfidf_SVC.predict_proba([sentence])[0]\n",
    "\n",
    "    result = f\"The predicted dialect is: {prediction}\\n\"\n",
    "    result += \"Prediction probabilities for each dialect:\\n\"\n",
    "    for dialect, probability in zip(saved_model_tfidf_SVC.classes_, probabilities):\n",
    "        result += f\"{dialect}: {probability:.4f}\\n\"\n",
    "        \n",
    "        if probability < minimum_probability:\n",
    "            minimum_probability = probability\n",
    "        \n",
    "        if probability > maximum_probability:\n",
    "            maximum_probability = probability\n",
    "        \n",
    "        # Create a map centered around Arabic countries\n",
    "    m = folium.Map(location=[24, 43], zoom_start=4)\n",
    "\n",
    "    # Add a marker for the predicted dialect country\n",
    "    predicted_country = prediction[0]\n",
    "    folium.Marker(location=get_country_coordinates(predicted_country, 0)[0],\n",
    "                  popup=f\"Predicted: {predicted_country}\",\n",
    "                  icon=folium.Icon(color='green', icon='info-sign')).add_to(m)\n",
    "\n",
    "    # Add heatmap layers for each Arabic country\n",
    "    for dialect, probability in zip(saved_model_tfidf_SVC.classes_, probabilities):\n",
    "        proximity_score = 1 - probability  # Calculate the proximity score\n",
    "        normalized_score = (proximity_score - minimum_probability) / (maximum_probability - minimum_probability)\n",
    "        coordinates, color = get_country_coordinates(dialect, proximity_score)  # Get coordinates and color\n",
    "        folium.CircleMarker(location=coordinates,\n",
    "                            radius=10,\n",
    "                            color='{}'.format(color),\n",
    "                            fill=True,\n",
    "                            fill_color='{}'.format(color),\n",
    "                            fill_opacity=0.7).add_to(m)\n",
    "\n",
    "    # Save the map as an HTML file\n",
    "    map_file = 'heatmap_SVC.html'\n",
    "    m.save(map_file)\n",
    "\n",
    "    # Open the HTML file in a web browser\n",
    "    webbrowser.open(map_file)\n",
    "\n",
    "    messagebox.showinfo(\"Prediction\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6631a7-d714-4f88-818b-acee18660071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "root.title(\"Arabic Dialect Predictor - SVC Model\")\n",
    "\n",
    "label = tk.Label(root, text=\"Enter an Arabic sentence:\")\n",
    "label.pack()\n",
    "\n",
    "entry = tk.Entry(root, width=50)\n",
    "entry.pack()\n",
    "\n",
    "button = tk.Button(root, text=\"Predict\", command=predict_dialect)\n",
    "button.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47f433-75a9-48fc-b916-ede0afaa4da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
